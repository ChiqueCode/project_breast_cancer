{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset from sklearn\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Display dataset information\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature and targets\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "\n",
    "# Split into training and testing data; not sure if y should be stratified. Must look into this more\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train.reshape(-1, 1))\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.916083916083916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/PythonData/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Figure out whether we should be using scaled data or not; update as necessary\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train_scaled, y_train)\n",
    "log_score = log_model.score(X_test_scaled, y_test)\n",
    "print(log_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.641, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.627, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.627, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=1, gamma=0.0001, kernel=linear, score=0.937, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.627, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.627, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=1, gamma=0.0001, kernel=sigmoid, score=0.627, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.859, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=1, gamma=0.001, kernel=linear, score=0.937, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.831, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.810, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=1, gamma=0.001, kernel=sigmoid, score=0.810, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.880, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.908, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=1, gamma=0.01, kernel=linear, score=0.937, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.901, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.880, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=1, gamma=0.01, kernel=sigmoid, score=0.915, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=5, gamma=0.0001, kernel=rbf, score=0.831, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=5, gamma=0.0001, kernel=rbf, score=0.810, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=5, gamma=0.0001, kernel=rbf, score=0.810, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=5, gamma=0.0001, kernel=linear, score=0.944, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=5, gamma=0.0001, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=linear ................................\n",
      "[CV] .... C=5, gamma=0.0001, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=5, gamma=0.0001, kernel=sigmoid, score=0.746, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=5, gamma=0.0001, kernel=sigmoid, score=0.732, total=   0.0s\n",
      "[CV] C=5, gamma=0.0001, kernel=sigmoid ...............................\n",
      "[CV] ... C=5, gamma=0.0001, kernel=sigmoid, score=0.746, total=   0.0s\n",
      "[CV] C=5, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=5, gamma=0.001, kernel=rbf, score=0.901, total=   0.0s\n",
      "[CV] C=5, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=5, gamma=0.001, kernel=rbf, score=0.880, total=   0.0s\n",
      "[CV] C=5, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=5, gamma=0.001, kernel=rbf, score=0.894, total=   0.0s\n",
      "[CV] C=5, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=5, gamma=0.001, kernel=linear, score=0.944, total=   0.0s\n",
      "[CV] C=5, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=5, gamma=0.001, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=5, gamma=0.001, kernel=linear .................................\n",
      "[CV] ..... C=5, gamma=0.001, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=5, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=5, gamma=0.001, kernel=sigmoid, score=0.887, total=   0.0s\n",
      "[CV] C=5, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=5, gamma=0.001, kernel=sigmoid, score=0.880, total=   0.0s\n",
      "[CV] C=5, gamma=0.001, kernel=sigmoid ................................\n",
      "[CV] .... C=5, gamma=0.001, kernel=sigmoid, score=0.873, total=   0.0s\n",
      "[CV] C=5, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=5, gamma=0.01, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=5, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=5, gamma=0.01, kernel=rbf, score=0.915, total=   0.0s\n",
      "[CV] C=5, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=5, gamma=0.01, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=5, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=5, gamma=0.01, kernel=linear, score=0.944, total=   0.0s\n",
      "[CV] C=5, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=5, gamma=0.01, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=5, gamma=0.01, kernel=linear ..................................\n",
      "[CV] ...... C=5, gamma=0.01, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=5, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=5, gamma=0.01, kernel=sigmoid, score=0.923, total=   0.0s\n",
      "[CV] C=5, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=5, gamma=0.01, kernel=sigmoid, score=0.894, total=   0.0s\n",
      "[CV] C=5, gamma=0.01, kernel=sigmoid .................................\n",
      "[CV] ..... C=5, gamma=0.01, kernel=sigmoid, score=0.915, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.859, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.852, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=linear ...............................\n",
      "[CV] ... C=10, gamma=0.0001, kernel=linear, score=0.930, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.831, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.810, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=sigmoid ..............................\n",
      "[CV] .. C=10, gamma=0.0001, kernel=sigmoid, score=0.810, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.880, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.908, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=linear ................................\n",
      "[CV] .... C=10, gamma=0.001, kernel=linear, score=0.930, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.901, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.880, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=sigmoid ...............................\n",
      "[CV] ... C=10, gamma=0.001, kernel=sigmoid, score=0.894, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.923, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.915, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.930, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.951, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.923, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=linear .................................\n",
      "[CV] ..... C=10, gamma=0.01, kernel=linear, score=0.930, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.838, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.901, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=sigmoid ................................\n",
      "[CV] .... C=10, gamma=0.01, kernel=sigmoid, score=0.923, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  81 out of  81 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [1, 5, 10], 'gamma': [0.0001, 0.001, 0.01],\n",
       "                         'kernel': ['rbf', 'linear', 'sigmoid']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the GridSearchCV model\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01],\n",
    "             'kernel': ['rbf', 'linear', 'sigmoid']}\n",
    "svc = SVC()\n",
    "grid = GridSearchCV(svc, param_grid, verbose=3, cv=3)\n",
    "\n",
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "0.9366197183098591\n"
     ]
    }
   ],
   "source": [
    "# Find the best parameters based on gridsearch\n",
    "svm_param = grid.best_params_\n",
    "print(svm_param)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9300699300699301\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(C=1, gamma=0.0001, kernel=\"linear\")\n",
    "svm_model.fit(X_train_scaled, y_train)\n",
    "svm_score = svm_model.score(X_test_scaled, y_test)\n",
    "print(svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train_scaled, y_train)\n",
    "rf_score = rf.score(X_test_scaled, y_test)\n",
    "print(rf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, Train/Test Score: 1.000/0.937\n",
      "k: 3, Train/Test Score: 0.951/0.930\n",
      "k: 5, Train/Test Score: 0.946/0.930\n",
      "k: 7, Train/Test Score: 0.946/0.944\n",
      "k: 9, Train/Test Score: 0.939/0.944\n",
      "k: 11, Train/Test Score: 0.937/0.951\n",
      "k: 13, Train/Test Score: 0.939/0.944\n",
      "k: 15, Train/Test Score: 0.939/0.930\n",
      "k: 17, Train/Test Score: 0.932/0.930\n",
      "k: 19, Train/Test Score: 0.932/0.930\n",
      "k: 21, Train/Test Score: 0.930/0.930\n",
      "k: 23, Train/Test Score: 0.932/0.937\n",
      "k: 25, Train/Test Score: 0.927/0.937\n",
      "k: 27, Train/Test Score: 0.927/0.930\n",
      "k: 29, Train/Test Score: 0.927/0.923\n",
      "k: 31, Train/Test Score: 0.927/0.923\n",
      "k: 33, Train/Test Score: 0.927/0.923\n",
      "k: 35, Train/Test Score: 0.927/0.923\n",
      "k: 37, Train/Test Score: 0.925/0.923\n",
      "k: 39, Train/Test Score: 0.927/0.923\n",
      "k: 41, Train/Test Score: 0.925/0.923\n",
      "k: 43, Train/Test Score: 0.923/0.923\n",
      "k: 45, Train/Test Score: 0.920/0.930\n",
      "k: 47, Train/Test Score: 0.918/0.930\n",
      "k: 49, Train/Test Score: 0.918/0.930\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd3hUddbA8e9JSKMkoSZ0giCKhSpKVVEBu2LFsnas6767awF1dZfVxbWsu1jWihV7QVTKIqCAKM1QpCMBIfQSanrO+8e9gSFMkpswk5lkzud55nHmzi3nxmHO3PsrR1QVY4wxpqSoUAdgjDEmPFmCMMYY45clCGOMMX5ZgjDGGOOXJQhjjDF+1Qp1AIHSqFEjbdOmTajDMMaYamX+/PnbVbWxv/dqTIJo06YN8+bNC3UYxhhTrYjIutLes1tMxhhj/LIEYYwxxi9LEMYYY/yyBGGMMcYvSxDGGGP8ClqCEJHRIrJVRH4p5X0RkVEislpEFolIV5/3bhCRVe7jhmDFCDA2PZPeT04lbdg39H5yKmPTM4N5OGOMqTaCeQXxFjCojPfPBdq7j6HAfwFEpAHwGHAq0AN4TETqByPAsemZDP98MZlZ2SiQmZXN8M8XW5IwxhiCmCBUdTqws4xVLgbeUcdPQLKINAUGApNVdaeq7gImU3aiqbSnJ60gO7/wsGXZ+YU8PWlFMA5njDHVSijbIJoD631eb3CXlbb8CCIyVETmici8bdu2VTiAjVnZFVpujDGRpFo3Uqvqq6raXVW7N27sd6R4mZolJ1RouTHGRJJQJohMoKXP6xbustKWB9z9AzuQEBN92LKEmGjuH9ghGIczxphqJZQJYhzwO7c302nAblXdBEwCBohIfbdxeoC7LOAu6dKckYNPIq6W82donpzAyMEncUkXv3e0jDEmogRtsj4R+QA4A2gkIhtweibFAKjqy8B44DxgNXAAuMl9b6eI/B2Y6+5qhKqW1dh9VC7p0pzpK7cxO2MnPwzrH6zDGGNMtRO0BKGqQ8p5X4G7S3lvNDA6GHH5k5IUz5Y9ORQVKVFRUlWHNcaYsFatG6kDpWlSPAVFyvb9uaEOxRhjwoYlCCAlMR6ALbstQRhjTDFLEECqmyA278kJcSTGGBM+LEHg3GIC2LzbBsgZY0wxSxBAw7pxREeJXUEYY4wPSxBAdJSQUi+OTbstQRhjTDFLEK7irq7GGGMcliBcqYnxbLYrCGOMOcgShCs1yRKEMcb4sgThSk2MZ39eIXtz8kMdijHGhAVLEK5Ut6urtUMYY4zDEoSreLCc9WQyxhiHJQhX6sHBcpYgjDEGLEEcVDwfkyUIY4xxWIJwxcdEU792jI2mNsYYlyUIHymJNljOGGOKWYLw0TQp3hqpjTHGZQnCR6pNt2GMMQdZgvCRkhjP9n155BUUhToUY4wJOUsQPpraYDljjDnIEoSPg6VHLUEYY4wlCF9NkxIAKz1qjDFgCeIwqTZYzhhjDrIE4SMxoRbxMVGWIIwxBksQhxERmiYlsMluMRljjCWIklIS49hiVxDGGGMJoqTUxHhrpDbGGCxBHCE1KYEte3IoKtJQh2KMMSFlCaKE1MQ48guVnQfyQh2KMcaElCWIElKLx0JYO4QxJsJZgijBKssZY4zDEkQJBwfLWUO1MSbCWYIooXG9OKKjxK4gjDERzxJECdFRQuO6cXYFYYyJeJYg/EixwkHGGGMJwp+miVZ61BhjLEH4kZoUb9NtGGMiXrkJQkQSRGS4iLzsvm4nIucGP7TQSUmMZ29uAftyC0IdijHGhIyXK4jRgAB93NcbgX8ELaIw0NTGQhhjjKcE0V5V/wHkA6jqAZyEUS4RGSQiK0RktYgM8/N+axGZIiKLROQ7EWnh895TIrJERJaJyCgR8XTMQLDSo8YY4y1B5IlIPKAAIpIGlDtRkYhEAy8C5wIdgSEi0rHEas8A76jqycAIYKS7bS+gN3AycCJwCnC6lxMKhOIrCGuoNsZEMi8JYgQwEWghIm8D04DhHrbrAaxW1TWqmgd8CFxcYp2OwFT3+TSf9xWIB2KBOCAG2OLhmAFRPN2GXUEYYyJZmQnCva2zELgCuA34AuihqlM87Ls5sN7n9QZ3ma+FwGD3+aVAPRFpqKo/4iSMTe5jkqou8xPfUBGZJyLztm3b5iEkb+JjoklKiLE2CGNMRCszQaiqApNVdZuqfqmqY1V1awCPfx9wuoik49xCygQKRaQdcDzQAiep9BeRvn7ie1VVu6tq98aNGwcwLOc2k91iMsZEMi+3mBaISJdK7DsTaOnzuoW77CBV3aiqg1W1C/CwuywL52riJ1Xdp6r7gAlAz0rEUGkpiTaa2hgT2bwkiC7AXLc30s8iki4iP3vYbi7QXkTSRCQWuBoY57uCiDQSkeIYhuN0qQX4DefKopaIxOBcXRxxiymYrPSoMSbS1fKwzkWV2bGqFojIPcAkIBoYrapLRGQEME9VxwFnACNFRIHpwN3u5p8C/YHFOA3WE1X1q8rEUVmpSfFs35dLfmERMdE24NwYE3nKTRCq+quInAAUtwHMUNUlXnauquOB8SWWPerz/FOcZFByu0Lgdi/HCJbUpHhUYeveXJonJ4QyFGOMCQkvU23cA3wCtHIfH4vIXcEOLNQOVZbLDnEkxhgTGl5uMQ3F6dq6D0BE/gHMAl4KZmChdrCy3O7cEEdijDGh4eXmunD4yOl8PE61UZ1Z6VFjTKTzcgXxLjBbRD5zX18KvB28kMJDcu0Y4mpF2S0mY0zE8tJI/ZSIfMeh2VzvUNW5QY0qDIgIqUnxbN5jt5iMMZGp3AQhIqcAS1V1jvu6noh0V9V5QY8uxFISrXCQMSZyeWmDeBU44PN6P/BKcMIJL02T4tm0x24xGWMik5cEEaWqRcUv3OcxwQspfKQmxrNldy7OlFTGGBNZvCSIDBG5U0SiRSRKRO4G1gY5rrCQmhRPXmERO/eXW/7CGGNqHC8J4nbgLJx6DFtx5kW6LZhBhQvr6mqMiWReejFtAS6vgljCTopP4aATmiWFOBpjjKlapV5BiMjNbl0GxPGqiOxwZ3TtXHUhho6VHjXGRLKybjH9CVjnPr8Kpy50R+AhYFSQ4woLjevGESVYV1djTEQqK0EUqGq++/xC4G1V3aKqE4G6wQ8t9GpFR9Gobpy1QRhjIlJZCUJFJEVE4nAaqb/1eS9i5r+20qPGmEhVViP1X4HiynETVPUXALc2dEaQ4wobKYnxrN2xP9RhGGNMlSs1QajqlyIyAUhS1W0+by3AKR8aEZomxfPTmh2hDsMYY6pcmeMgVDWvRHJAVfeq6p7ghhU+UpLi2ZNTwIG8glCHYowxVcqKLZfjUOEga4cwxkQWSxDlOFR61BKEMSayeKlJ/ZGIDBSRGl9Fzh+bbsMYE6m8XEG8CdwMrBSRx4tHV0eKg1cQliCMMRGm3AShqhNV9SqgB7AZmCYi00XkehHxUrK0WqsdW4vE+Fp2i8kYE3E8tUGISH3gGuB6YBFOwaBewMTghRY+UpPiLUEYYyKOl5KjnwAnAWOAy1R1g/vWGBFJD2Zw4SI1KYEtdovJGBNhvNwiehX4Vv2UVVPVLoEPKfykJsaxfFPEDP0wxhjA2y2mY4CDxRBEpL6IDA1eSOEnNTGebftyyS8sKn9lY4ypIbwkiDtUNav4haruAu4MXkjhJzUpAVXYtjc31KEYY0yV8ZIgon1fiEgUEBOccMJTalIcYF1djTGRxUsbxGQR+QB42X19B4dP/V3jpbiD5axwkDEmknhJEPcDdwF/dF9PxunmGjGaJjnlL6wuhDEmkpSbIFS1EHjefUSk+rVjiK0VZV1djTERxcs4iGOAJ3DqUccXL1fVY4MYV1gREVIT460NwhgTUbw0Ur+FMx+TAOcCHwMfBTGmsJSaaKVHjTGRxUuCqK2qkwBU9VdVfQQnUUSUlKR4u8VkjIkoXhJErtu19VcRuUNELgTqBTmusNM0ybmC8DOg3BhjaiQvCeKPQB3gXqA3cCvO9N8RJSUxnryCIrIO5Ic6FGOMqRJlNlKLSDRwqarOBvbizOYakXwLB9WvExviaIwxJvjKvIJwu7ieWUWxhDUrPWqMiTRebjHNF5HPRWSIiFxU/PCycxEZJCIrRGS1iAzz835rEZkiIotE5DsRaeHzXisR+Z+ILBORpSLSxvNZBYFVljPGRBovI6nrAfuB83yWKTCurI3c21MvAucAG4C5IjJOVZf6rPYM8I6qvi0i/YGRHLqN9Q7whKpOFpG6QEinUm1SLw4Ru4IwxkQOLyOpK9vu0ANYraprAETkQ+BiwDdBdAT+5D6fBox11+0I1FLVyW4M+yoZQ8DEREfRqG6cJQhjTMTwMpL6VX/LVbW8mhDNgfU+rzcAp5ZYZyEwGPgPcClQT0QaAscCWSLyOZCGMzngMLdNxDe2ocBQgFatWpV3KkfNRlMbYyKJlzaIKT6PH4AmQKAKI9wHnO6WLj0dyAQKcRJXX/f9U4C2wI0lN1bVV1W1u6p2b9y4cYBCKp3VpjbGRBIvt5gOm1ZDRN4FZnrYdybQ0ud1C3eZ77434lxB4LYzXKaqWSKyAVjgc3tqLHAa8IaH4wZNamI8czJ2hjIEY4ypMl6uIEpKA1I8rDcXaC8iaSISC1xNiYZtEWnkjtIGGA6M9tk2WUSKLwv6c3jbRUikJsWzOzuf7LzC8lc2xphqrtwEISK7RGSn+8jCqQcxvLztVLUAuAeYBCwDPlbVJSIywqeb7BnAChFZiZN0nnC3LcS5vTRFRBbjTBT4WoXPLsB8B8sZY0xN56WbayOf50VagcmIVHU8ML7Eskd9nn8KfFrKtpOBk70eqyr4DpZLa1QnxNEYY0xwebnFdD5QV1ULVVVFJFlELgh2YOGoOEHYrK7GmEjgJUGMUNXdxS9UNQv4e/BCCl/Ft5isLoQxJhJ4SRDiZ5mXW1M1Tp24WtSLq2VXEMaYiOAlQaSLyFPuvEmtReRpID3YgYWr1KR4Nu3ODnUYxhgTdF4SxD3uel/iTIWhwF3BDCqcpSbFs3lPoMYJGmNM+PIyUG4fTpdTg1M4aNWW7aEOwxhjgs7LOIiJIpLs87q+iHwT3LDCV9OkeLbuzaGgMKSTyxpjTNB5ucWU4vZcAkBVdwHNghdSeEtJjKdIYfu+vFCHYowxQeUlQRSVLOQTxHjCXlMrHGSMiRBeuqs+CvwgIlNxuryeAdwZzKDCWUrxdBu7s6FlcjlrG2NM9eWlkfobEekB9HQXPaCqW4MbVviy2tTGmEjhdTbXHOA3YCvQTkR6BS+k8Nagdiyx0VHW1dUYU+N5qSh3M/BnnApxi3EK+PyEc6sp4kRFCU0S45xbTMYYU4N5uYL4I9AdWKuqfYFuwI6gRhXmakTp0Zn/hozphy/LmO4sN8YYvCWIHFXNBhCRWFVdAnQIbljha2x6Jks27uanNTvp/eRUxqZnlr9ROGreFT658VCSyJjuvG7eNZRRGWPCiJdeTJvcgXJfAZNEZCewIbhhhaex6ZkM/3wx2fnOILnMrGyGf74YgEu6NA9laBWX1g+ueAs+GALNusDWpc7rtH6hjswYEybKvYJQ1YtUNUtV/wI8DowBLg56ZGHo6UkryM4/vNxodn4hT09aEaKIjpJEQd4+WDsDWvSw5GCMOUyFalKr6hRV/VxVI7ILz8Ys/w3TpS0Pa/u2wofXOUkiqSWsnAA/vxvqqIwxYaRCCSLSNUtO8Ls8uXZMFUdylIoKYczlkLMLLvg33DoF4pPhqz/Aykmhjs4YEyYsQVTA/QM7kBATfdiyKIFdB/J5+ftfqUC57tCa/gxsWgg974FuN0C9FLjqXdAimPo4VJfzMMYElSWICrikS3NGDj6J5skJCNA8OYGnLjuZCzs148kJy/nbV0spLArzL9c138N3I+GkK2HA44eWp/WDMx+CzYvg57dDF58xJmx4GSi3C6dIkK/dwDzgflVdG4S4wtYlXZof0WNpcNcWpNSL4/WZGWzdm8O/ruxMfIkrjbCwdwt8dis0ag8XPAdSopps3z/Dulkw/gFo3g1STwpNnMaYsODlCuJF4C/AMe7jEeATnOpybwYvtOojKkp45IKOPHL+8YxfvJnfvTGH3QfyQx3W4YoK4bNbIHcvXPE2xNU9cp2oaBj8GtRuAB/fADl7qj5OY0zY8JIgLlTVF1V1l/t4CRigqmOABkGOr1q5tW9bnh/ShQXrs7j85VlkhlPvpu//6XRnPf8ZSOlY+np1G8Nlb8CuDKfR2tojjIlYXhJEtogMLn7hPi/u5mpl1Uq4sFMz3rr5FDbvzuGyl2axfHMY/Ar/dSp8/xR0uga6XFf++m16Q/9HYMnnMO+N4MdnjAlLUl7PGxFpBzwPnIrTFjEH+APOaOpTVPX7YAfpRffu3XXevHmhDuOg5Zv3cOPouezPLeD6Xq35Mn0jG7OyaZacwP0DO5Q78npseiZPT1pRoW382rMJXu4DdRrBbVMhto637YqK4P0rIeN7uGUyNOtc8WMbY8KeiMxX1e5+36s2XTPLEW4JApwBdJe++ANb9h4+rjAhJpqRg08q9Qv/0JQehZ638auwAN65CDamw23ToMlxFTuB/Tvglb4QHQO3T4f4pIptb4wJe2UlCC+9mBoBNwNtfNdX1aGBCrCmapacQFSUHLE8O7+Qh75YzE9r/E+KO27hxlKn9KhQgvjuH7DuB7j0lYonB4A6DeHy0fDmefDlPXDlO0f2fDLG1FheJuv7Eqf+w0ygsJx1TQmlVZ47kFfItBX+C/MdyPP/Z67QlB6rvoUZz0KX66HT1d63K6nVaXD2YzD5UZjzKpx6e+X3ZYypVrwkiDqq+uegR1JDNUtO8NubqXlyAj8M6+93m95PTvW7TWlTfRxhdyZ8fhs0OQHOe7pC8frV8/fO+IhJD0OL7s4YCWNMjeelF9MEERkQ9EhqKH/TcyTERHP/wNJLarzSdianxyw7bFmfWkt5pe1M/xv4Fv8pzIdPb4b8A9CuP8R4TCpliYqCS/4LsbXh/ashe9eh96zIkDE1lpcEcQcwUUT2ichOEdnl1oQwHvibnqO8xuYTTzmDVxNe4MJ6qxGgX8wy/hP9H+qkneJ/A9/iP1Mfh/U/QVQtaB/AvF67AZz5F9i/Fd6/yhkfYUWGjKnRvHRz9TtnhKqGVXtEOPZiOiqrvoUProLoWDQ/mz3UpkBiqF871n9WL8yDnN2AQq04uPbT4NR3+PpPztiIYwfBhrlWZMiYaq5SvZhEpL2qrgJOKGWVRYEIzpQidzcUFUBRAdK0E7n1TuDbZVtoVas2vds1wm9foo0/O7O0nnZ38L60z38Wln0FKydCvwcsORhTg5XVSD0MuAVnLqaSFLBvhmCa9YJTzKfPn2D+mzQZ8Di7mzXnuonLebzniVx3WuvD18+YDsvGOV/a896AY84Mzpf32hmQt995PucVSOtrScKYGqrUNghVvcV92l9V+/o+gLOqJrwI9csXztXAiZfDWX9xbuN8ciO3t9zAGR0aM+LrpSzZuPvQ+sVtAVe8Bf0fPrj+wYbrQCk+zuDXIDoW2pwenOMYY8KCl0bq2R6XmUBZ8J7z3zOGOf9N6wdXvEXUpnSevaITDWrHcs/76ezNcWeMzfz58LYAd30yfw5sXMXHOf586HAu/PYDDH498McxxoSFUhupRaQJ0BT4ELgSDt72TgReV9VKDM0NnhrTSK0KL3SHOo3h5ol+V5mTsZMhr/3EeSc1ZdTVnZFQjG5eOcmZq+mq9+D4C6v++MaYgCirkbqsK4jzgReAFjjtEMWPh3DqQ5hg2DAXdqyGzteWukqPtAb86Zxj+WrhRj6Ys74Kg/NxzFlQNwUWvB+a4xtjgq6sNog33faGW1S1n08bxHmq+omXnYvIIBFZISKrRWSYn/dbi8gUEVkkIt+JSIsS7yeKyAYReaHCZ1Zdpb8HMbXhhEvKXO3O04+h37GN+etXS1i6MQRTikfXgpOvcq4k9vmfMsQYU715aYNoIiKJACLysojMEZFyG6nd8RMvAucCHYEhIlKyUs0zwDuqejIwAhhZ4v2/A5HTApp3AJZ8AR0vhrh6Za4aFSU8d2Un6teO4e73f2ZfbkEVBemj87WghbDo46o/tjEm6LwkiKGqusedbqMpcBvwlIftegCrVXWNqubhtGVcXGKdjsBU9/k03/dFpBuQAvzPw7FqhuVfQ+4e6HyNp9Ub1o1j1NVdWLdjPw99vpgqn7q9yXHOvEwLxljlOWNqIC+T9RX/yz8P59f+QhHxkliaA743yDfgFB3ytRAYDPwHuBSoJyINgV3As8B1wNkejlUzLBgDya2gdR/Pm5zatiF/HtCBpyetYPrKbezOzj+6AkPlKFnI6MVjz6fzohGwaQE061Lu+sGKyxgTeF6+6BeKyHjgApyJ++pyKGkcrfuA00UkHTgdyMSZUvwuYLyqbihrYxEZKiLzRGTetm3bAhRSiGSthzXfO2VBo7z8bzmkWWI8UQJZ2fkokJmVzfDPFzM2PTOgIRYXMsrMyj54nNvTW1MYFQvpYzytH4y4jDHB4eUK4iagG87togNuAaFbytkGnC/7lj6vW7jLDlLVjThXELiJ5zJVzRKRnkBfEbkLqAvEisg+VR1WYvtXgVfB6ebqIabwtfBDQKHzkApv+szklRSVOPtKFRgqx9OTVhxRyGhLfgITpTtnzP+Qh3ZeTkFU7MH3pi7fQnb+4WXLgxGXMSY4yv2p6k7K1xa4012U4GU7YC7QXkTSRCQWuBoY57uCiDTyuV01HBjtHvNaVW2lqm1wrjLeKZkcahRV5/ZSm75Qv02FNy+tkFBmVjb5hUV+36uIoiJl2oqtfmtUAHxU0Jc6RXtpuHEKK7bsPfgomRzKi9cYE168lBx9AYjBmXvpCWA/8DJQytzTDlUtEJF7gElANDBaVZeIyAhgnqqOA84ARoqI4vRWuvsozqX6+u1H2JUBpz9Yqc1LK0oE0Pef07ixdxuGnNKKpNoxFdpvTn4hX6Rn8sbMDFZv3UeUcMSVCkBGvVMgthmPpi6Aax8+uPyoCx8ZY0LKy5VAL1W9HcgBUNWdQGzZmzhUdbyqHquqx6jqE+6yR93kgKp+qqrt3XVuVdVcP/t4S1Xv8XxGFeFbaKdYKArgpI+B2LrQ8aJKbe6/KFEUQ/ul0a5JXZ6csJyeT07hr+OWsG7H/nL3t21vLv+avJJeT05l+OeLiY+J4t9Xdeapy072W/zoz4M6OmVNV38LezaVGRfAlae0OGJZ2KvMZyVcPl/GVJKXNoh89zaQAri9jI7+vkU4KC60M+AJZ9DXupmHJr2rKrn7nLEPJ14KsXUqtYvi+/ml9RZaunEPo3/IYMzsdbz941oGdEzh1r5t2bDzAM/8b+XBba47rRUZ2/czNn0j+UVFnHVcCrf2TePUtAYHp/OoFR3l/zjbr4WZ/4JFH0Gf//MbV2pSPNl5hXwybwM39kojKaFiVzQhVfxZueItp5Trb7Ng3L1w0SjYv93/Ng2PgY9vgIueh+POd2bCrerPlzFHoay5mGq5t4l+h9MFtTtOG8GVwN9U9cOqC7N8lZ6LKf19+PJOaNMHti6r+gI4C96HsXfCTROgda+gHmrrnhze+XEd781eR9aBfESOHL5QKwqG9GjNTb3b0LZx3Yod4I0BTjnSu+dAKfNDpf+2iyte/pGzjm/Cy9d1C808UpW15nsYcwUUHnGhW74mHWHfFiuwZMJOpQoGAXOArqr6jojMxxmPIMAVqvpLEOIMjc5DYNYoWDsTTr666v/xLngf6qdBq55BP1STxHjuG9iBu89sx2kjp7A7O/+IdRrXi+fvl5xYuQN0vha+uhcy50MLv583urSqz7Bzj+Pxb5bx1qy13NQ7rXLHCoWdvx5KDu3OdqrqeZH+rlPIqd3ZlhxMtVJWgjj4005VlwBLgh9OCKyd4fyyS6jv3B457vxKtwVU2M4M5/hnPlLqL+5gSIiNZo+f5ACweXdO5Xd8wqUw4UFnPqlSEgTALX3S+GnNDv4xfhldW9WnU8vkyh+zqmxaCOMfgKgY6P1/MH809P5D+V/4GdNh9wZo0NZpo5k3GrrfXDUxG3OUymqkbiwifyrtUWURBlNxAZwr34YbvoaoWvDpzfDrd1Vz/IUfAuI08Fax0noSHVUPo/hEJ7n+8jnkl96VVUR45opONKkXzz0f/Oz3Sias5OyB969y5p264k046xFvRZl8CzndOgVqN4Jv/gzLx1dN3MYcpbISRDTOILV6pTyqP99CO6knwgX/gqJ8+KEKepkUFcHC96Ht6ZDcsvz1A8x/z6do7h/Y4eh23Pkap5728m/KXC25diyjhnRhU1YOD366qOrnkfJKFcb9HvZuhoEjD9W+8FKUyffzVbsBDPnAWT7lbzZ3lakWyrrFtElVR1RZJKHg9rY5qMv1sPYH51bTmu+g7RnBO/a6mZD1G/QPTWmN8no+VVqbfpDU0hn4d9LlZa7arXV9HhjUgX+MX847P67jhl5tju7YwTD3dVg6Fs7+K5x2x+HvpfUr+xZTyc9Xyx5wzgj43yMw+5Uj92dMmPHUBhExRJyriI3p8NmtcMdMqJcanGMteB/iEuG4C4Kzfw8u6dI88FNeREVBpyEw/WnYnQlJZe//1j5tmb1mJ098s4wurZI5uUUYtUdsTIdJD0H7AdDrD4HZZ897YN0sJ0m0OAVadAvMfo0JgrJuMZVb86FGiq3jtEnk7XeSRGEQ6izk7oWlXzqNurG1A7//UOs8BFBY+EG5q0ZFOe0Rjeo6dbb35IRJe0R2ljOGoU4TuPSVCk+gWCoRuOQlqNfUaZ/I3hWY/RoTBGVVlNtZlYGElSbHw/nPOj2Mvn8y8PtfMhbyD0CX6wK/73DQoC207u1cJXm4116/TizPX9OFzKxshn0WBu0RqvDl3bAn02mUrt0gsPtPqO+0TezdBGPvtvYIE7YC9LOoBup8DXS+DqY/A6unBHbfC8ZAw/bOLYaaqvO1zriB9bM9rd6tdQMeGNiB8Ys38+5P64IcXDlmv+wUbzrrMafdIBhadHPaI1Z8Az++GJxjGHOUSh1JXd1UeiR1WfIOwOtnOeMk7pgJic2Ofp87fhHOnocAABR2SURBVIXnuzpfPn1rRm9hv3L3wTPHwkmXOVNNeFBUpNzy9lymr9xGg7pxbN+b67nxPGCFiTbMh9EDnUFtQz44bHxKwIsfqcJH18HKiXDTRGhZg38wmLBV1khqu4IoS2xtuOJtyM+BT28JTHvEgvdBokIy9qFKxdWFEy6BX75w2nM8iIoSzjo+hUJ1Jgz0WmQoYIWJsnc57QL1mjrtBCWSQ8CLH4nAxS9CYnPnuAci966uCU9eJuuLbI2PhQuegy+GwrTHne6OlVVU6DTcHtM/MFcj4a7zNc7ttGVfQ6erPG3y3+9+PWJZdn4hD362iM9L+TKevWYHuQVHWZhI1WkP2LsJbp54RLuDv2JJASl+lJDstEeMHghf3AFDPgxcg7gxR8k+iV50ugq6/g5mPgerJld+PxnfOw2fna8JXGzhrFUvSG4NC97zvElpxYRyC4rYk53v91EyOZS3L79+fNFpDzhnxBHThKzasrfUehsBKX7UvKszo/CqSc68YMaECUsQXp37FNRNgU9ucubWKVaRmgAL3of4JIhLioyaALNGOb2ZMqY7gwKh3L/XfXUn0jPq8Gm/ekYt4f66Exl7d2+/j/tL2WZo9Ffc/NZcZq3efnjPqJJ1GtbPhcl/gcbHwWlO4URVZcaqbdwweg7nPFf6dBpNEuM8/jHK0eM26HgJfPtXp5Hcl9WQqH4qWgskTOuNWILwKiYBzv4b5O2F9y6DwvxDc+0071r6dsV1BJaPh2VfOb+qvxha9jY1RfOusHKC83zBB57+Xp16nMmLMaMOfuH3jFrCizGj6NTjzApvE9e6GwvXZ3HN67M5b9RMPpu/gbyCokP/TzKmO/f9P3Dbg856jNzCIj6et55B/57B9W/MYemmPdw34Fgev+REv8WPsvMKWLZpT6X+PIcRcWpL1E2BicOd23Lg7TNmwo/vZwzK//9Y0fUru00FWS+mipryOMx4Gpp2hp1r4PQHIPXksrfZvAimPgEF2c4VxFXvRc60zxnT4d3BEFMbUE9/r8XzZ9BmyYtMLuzKOdE/s/aEuzmpW99KbZNXWMQPq7czfvEmNmTlUD8hhgEnpNAydzXHrvgvO4rq0TpqC7M7Psychpfyzo/r2L4vl+NS63Fr37Zc2KkpcbWcxFCyF9O1p7XinVnr2J9bwCu/60avYxod/d9r00J4zR2jWjxrrNWQqJ4ypsNH18OxA2HFhPI/+5sXwfdPQYdzva3vu03Hi2HF+Ep9VsrqxWQJojJeOR02Lajctv3uh/6PBDaecPfhtc64gjD1XeHJ3Jg/DIAzOjTmtr5t6XVMQ0/FjDZmZXPjm3PI2L6fZ6/szEWdAtD5YO4b8I3bBbrfA9D/4bLXN+Fp1WQYU/Z8ZAFVyc9KZQsGGX8ypsPu9c4o6KXj4Izh0LRT2dtsWgjfjXQmA5w3uvxJ3mqSjOnw24+V+3sdd74zK2yAt7n93Xk0y17FH2M+46vC0xgUPZeeUUv4tU5X3rqpYgPjmiUn8Mntvbjt3Xnc+0E6W/fkcGvfthXaxxEatoPoWCjMc9oj0vpGzuelpti9wWmvlGg4+QrnFnN5n+Oj+dyfcCnMeyPwnxVVrRGPbt26adCt+V71n2nOf/29DtQ2NUVV/b0quM3Vw/+p2x9trlcP/6e2fvDrw15XVnZegd753jxt/eDXOuKrJVpYWFS5HRXHvmKC6qiuqiNbqz7ZOjI+LzVFQZ7qCz1UH0tUTX/fWVbe5ziE3y3APC3le9UaqSvCd35/qHhNAK/b1BRV9feq4DZ9aq/nnvx7+bHoBAB+LDqBe/LvpU/t9d7PrYT4mGieH9KVG3u14Y2ZGfz+w3RyCwrL37Ck4nM5dpAzSLMg2+kqvGF+pWMzVWzKCNi23Lmd3HmIs6y8z3GYfrdYG4SJOMWjon0HviXERDNy8ElHPf25qvLq9DWMnLCcU9MacHGXZrw49dcKTc/h2xh+e92ZDCt4Cc582Gm0LGf9YE5NUtFtAj41SYiP48mKifDBVdD9Fqd0QDVgjdTGlBDsL5Wx6Zn86eMFqILvv7DyEtGRyUsZFfsyF0b9gNzw5RH3lyuT7Kpim2Am4VAcx5Os3+DlvpDcCm6ZDDHxVXv8SrIEYUwIdPv7ZHbszztieVJCLf549rF+t3nu25Xszj58zq/a5PB1/F9oGpvDuNM+IjuuUZnrV+YYgd6mtPWbJyfww7D+fo9RGb2fnOp3lHugj1Ougjx481zYvhJu/96Z8r6asARhTAikDfuGQP3rOlbW82XsX0gvasd1+Q9RVE2bDwXIePL8gOxr/c4D9H1qWtCP48nEh+CnF512oxMuqbrjBoB1czUmBJolJ/j9dds0KZ7x9/of+HfeqBls2p1zxPK9ie0p6v8MvSbcy5I+C8jp82CZ61fmGIHcprT1FRj22SJu7pPGsSn1/B6rPD//tos3ZmQw4ZdNpa4TEx3FhMWbGHBCKtFRQa6evOxrJzn0GFrtkkN5qufPEGOqgfsHdjhieo6EmGgeHHQc9evE+n08OOi4Urepc+oN0PlaEn58lvqbZ5a7fmWOEaht/K0fVyuK3sc0YOyCTAY8N50bRs9h+sptnioIFhYp4xdvYvBLPzD4pVnMWLWNof2O4a8XdTziODHRQt34aO4c8zNnPDON0TMz2JcbhNLBALvWwti7oFkXGPB4cI4RQnaLyZggCnhvobz98Fp/2L/dLWLVtNr1Ytq1P4/35/zGW7PWsm1vLh1S6nFLnzQu6tyMib9sPmyb3/dvx4G8Qt6clcH6ndm0blibm3uncXm3FtSJq1XqcS7s1IzJS7fwxsw1zF27i3pxtRhyaitu6NWGuRk7A9NBoSDXmaZ9xxq4YzrUb1PxfYQBa4MwpibZuhxeO9P51fq7cRBdPe8U5xYU8vXCTbw2Yw3LN++lblw0OflFFBQd+Z3Uo00DbumbxtnHp1T4ltGC9Vm8MTOD8Ys3UVSkRIlQ6PO9V+leT+MfgDmvOHOrHX9hxbYNI5YgjKlpFn4IX9wOff8MZz0a6miOiqry4687uOmtuX5rezSuG8fcR84+6uNkZmUz8Lnv2Zd75ADGCvd6WjIWPrkBTrsLBo086thCyUqOGlPTdLramdtrxrOw6ttQR3NURIRe7Ro5U7H7sX1fbkCO0zw5gf1+kgM4yWO/13aKnWtg3O+heTenBEANZgnCmOrqvKehTopTA2C3TznWYBSaqYICOKUVi7qv7sSAxVXaMW6P/oqeI6cwcsIyNu0u0fPM9xj5OfDxDU754LR+UCu29NhqAEsQxlRXMQlwzlEUsQpmcZpKHKMyxaIqepzSjtGucz/6tm/Ma9PX0Pef0/jDh+ks3rD7yGNMesipwRAV5dSWr+GsDcKY6q64iFWT42HXb07N84bHlL3Njl+dEritToXfZgdnm0oc49fli2i69nPmFrbnlOhVbGozmGOOK6doTgWPU9Yxdh3IY07GTtJ/yyK3oJBWDevQs20DamVl0GLtZ8STRw6xzOv1Cn0GDC47rmrCGqmNqeleOwsy7fNfFZ4vuJiX5JrQzPcUBDaS2piaLGM67MqAXn+A9Hfh4hegda+yt1k3C768xynklP5ecLapimMEOa6CQqX/s9/RPncxT8e8yruF53Bd9LfMyj+RpyfF1ogEUabSCkVUt0eVFAwyJtyEaVGmmhRXWQWmFm/IKj22agIrGGRMDRWmRZlqUlylFZjqJGu44PmZXP3qj3y7dAtFfgb4VXfWBmGMMWUorebEoxcez76cQt78IYONu3NIa1SHm/ukcVnX5tSOrRVehYzKELJGahEZBPwHiAZeV9UnS7zfGhgNNAZ2Atep6gYR6Qz8F0gECoEnVPWjso5lCcIYEyxlfdnnFxYx8ZfNvD5jDQs37Ca5dgyntK7PjFXbyfEZ/BeyQkblCEmCEJFoYCVwDrABmAsMUdWlPut8Anytqm+LSH/gJlW9XkSOBVRVV4lIM2A+cLyqZpV2PEsQxphQUlXmr9vF6zMymLhks991qryQkQehmmqjB7BaVdeoah7wIXBxiXU6AlPd59OK31fVlaq6yn2+EdiKc5VhjDFhSUTo3qYBL1/fjdKmE9zopz5IOAtmgmgOrPd5vcFd5mshUDza5FKgnog09F1BRHoAscCvJQ8gIkNFZJ6IzNu2bVvAAjfGmKPRLDnB7/LoKGHM7HVk5/mfEyrchLoX033A6SKSDpwOZOK0OQAgIk2Bd3FuPR0xk5eqvqqq3VW1e+PGdoFhjAkP/opFxUQLqYnxPPzFL/R6cgrP/m8FW/ceWXUvnARzoFwm0NLndQt32UHu7aPBACJSF7isuJ1BRBKBb4CHVfWnIMZpjDEBVdwQXbJh++LOzZiTsZPXZ2bwwrTVvPL9Gi7q3Ixb+qSxYvPeKin8VBHBbKSuhdNIfRZOYpgLXKOqS3zWaQTsVNUiEXkCKFTVR0UkFpgAfKWqZUwxeYg1UhtjqpOM7ft584cMPpm3gez8QqIEfIdSlNfrqbTutxXtKRXKbq7nAf/G6eY6WlWfEJEROCP3xonI5cBInFrm04G7VTVXRK4D3gR85+W9UVUXlHYsSxDGmOoo60Ae/Z6axp6cI+tR1IoS0hrV8btdxvb9fqvvVbSnVMjmYlLV8cD4Esse9Xn+KfCpn+3eA94LZmzGGBMOkmvHstdPcgAoKFLap9T1+96qrfv8Lg9kTymbrM8YY0KsWXICmX6+2JsnJ/DStd38btP7yal+tymtB1VlhLoXkzHGRDx/vZ4SYqK5f2CHgG5TUXYFYYwxIVZar6eyGpsrs01F2WR9xhgTwUI11YYxxphqzBKEMcYYvyxBGGOM8csShDHGGL8sQRhjjPGrxvRiEpFtwLpyVmsEbK+CcMJVJJ9/JJ87RPb527mXrbWq+p0Ou8YkCC9EZF5p3bkiQSSffySfO0T2+du5V/7c7RaTMcYYvyxBGGOM8SvSEsSroQ4gxCL5/CP53CGyz9/OvZIiqg3CGGOMd5F2BWGMMcYjSxDGGGP8ipgEISKDRGSFiKwWkWGhjifYRGS0iGwVkV98ljUQkckissr9b/1QxhgsItJSRKaJyFIRWSIif3CX1/jzF5F4EZkjIgvdc/+buzxNRGa7n/+P3LrvNZKIRItIuoh87b6OpHNfKyKLRWSBiMxzl1X6cx8RCUJEooEXgXOBjsAQEekY2qiC7i1gUIllw4ApqtoemOK+rokKgD+rakfgNOBu9/93JJx/LtBfVTsBnYFBInIa8E/gOVVtB+wCbglhjMH2B2CZz+tIOneAM1W1s8/4h0p/7iMiQQA9gNWqukZV84APgYtDHFNQqep0YGeJxRcDb7vP3wYuqdKgqoiqblLVn93ne3G+LJoTAeevjuJixTHuQ4H+HKr/XiPPHUBEWgDnA6+7r4UIOfcyVPpzHykJojmw3uf1BndZpElR1U3u881ASiiDqQoi0gboAswmQs7fvcWyANgKTAZ+BbJUtcBdpSZ//v8NPAAUua8bEjnnDs6Pgf+JyHwRGeouq/Tn3kqORihVVRGp0X2cRaQu8Bnwf6q6x/kx6ajJ56+qhUBnEUkGvgCOC3FIVUJELgC2qup8ETkj1PGESB9VzRSRJsBkEVnu+2ZFP/eRcgWRCbT0ed3CXRZptohIUwD3v1tDHE/QiEgMTnIYo6qfu4sj5vwBVDULmAb0BJJFpPgHYU39/PcGLhKRtTi3kfsD/yEyzh0AVc10/7sV58dBD47icx8pCWIu0N7tzRALXA2MC3FMoTAOuMF9fgPwZQhjCRr3vvMbwDJV/ZfPWzX+/EWksXvlgIgkAOfgtMFMAy53V6uR566qw1W1haq2wfk3PlVVryUCzh1AROqISL3i58AA4BeO4nMfMSOpReQ8nPuT0cBoVX0ixCEFlYh8AJyBM93vFuAxYCzwMdAKZ2r0K1W1ZEN2tScifYAZwGIO3Yt+CKcdokafv4icjNMQGY3zA/BjVR0hIm1xflU3ANKB61Q1N3SRBpd7i+k+Vb0gUs7dPc8v3Je1gPdV9QkRaUglP/cRkyCMMcZUTKTcYjLGGFNBliCMMcb4ZQnCGGOMX5YgjDHG+GUJwhhjjF+WIEzEEZE2vrPcBnC/I0Tk7HLW+auI3FdVMRlzNGyqDWMCRFUfDdWxRSTanWLDmICxKwgT0USkrVs74JQSy88Qke9E5FMRWS4iY9wR2ohINxH53p0QbZLPNAZvicjl7vPz3O3mi8io4toEro7uvteIyL0+y2u5x1nmHre2u6+z3BgXi1PnI85dvlZE/ikiPwNXiMi94tTAWCQiHwbxz2YihCUIE7FEpAPOfE03qupcP6t0Af4Pp4ZIW6C3O8fT88DlqtoNGA0cNipfROKBV4Bz3XUal9jvccBAnHlyHnP3CdABeElVjwf2AHe5+3oLuEpVT8K56r/TZ187VLWrqn6IM89/F1U9Gbijwn8QY0qwBGEiVWOcOWmuVdWFpawzR1U3qGoRsABog/MlfiLOTJkLgEdwJoDzdRywRlUz3NcflHj/G1XNVdXtOBOnFU+/vF5Vf3Cfvwf0cY+Xoaor3eVvA/189vWRz/NFwBgRuQ6naJIxR8XaIEyk2g38hvMlvLSUdXzn6ynE+fciwBJV7XkUx/a3X3Dm8vflZR6c/T7Pz8dJHhcCD4vIST51EIypMLuCMJEqD7gU+J2IXFOB7VYAjUWkJzjTiovICX7WaesWKwK4yuO+WxXvF7gGmOnuq42ItHOXXw98X3JDEYkCWqrqNOBBIAmo6/G4xvhlVxAmYqnqfrfIzGQR2aeq5U4Br6p5bkP0KBFJwvk39G9gic862SJyFzBRRPbjTDfvxQqc+tmjca5q/quqOSJyE/CJW9NgLvCyn22jgffcmAQY5daDMKbSbDZXY4JAROqq6j6359OLwCpVfS7UcRlTEXaLyZjguM1txF6Cc7vnlRDHY0yF2RWEMcYYv+wKwhhjjF+WIIwxxvhlCcIYY4xfliCMMcb4ZQnCGGOMX/8PJm7uPcBA9SYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop through different k values to see which has the highest accuracy\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for k in range(1, 50, 2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    train_score = knn.score(X_train_scaled, y_train)\n",
    "    test_score = knn.score(X_test_scaled, y_test)\n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)\n",
    "    print(f\"k: {k}, Train/Test Score: {train_score:.3f}/{test_score:.3f}\")\n",
    "    \n",
    "    \n",
    "plt.plot(range(1, 50, 2), train_scores, marker='o')\n",
    "plt.plot(range(1, 50, 2), test_scores, marker=\"x\")\n",
    "plt.xlabel(\"k neighbors\")\n",
    "plt.ylabel(\"Testing accuracy Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9300699300699301\n"
     ]
    }
   ],
   "source": [
    "# Note that k=27 provides the best accuracy where the classifier starts to stablize\n",
    "knn = KNeighborsClassifier(n_neighbors=27)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_score = knn.score(X_test, y_test)\n",
    "print(knn_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min & Max Scaler \n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert encoded labels to one-hot-encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers \n",
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=70, activation='relu', input_dim=30))\n",
    "deep_model.add(Dense(units=70, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "deep_model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 70)                2170      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 70)                4970      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2)                 142       \n",
      "=================================================================\n",
      "Total params: 7,282\n",
      "Trainable params: 7,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print summary of the model\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "426/426 - 0s - loss: 0.6654 - acc: 0.6479\n",
      "Epoch 2/200\n",
      "426/426 - 0s - loss: 0.5661 - acc: 0.8286\n",
      "Epoch 3/200\n",
      "426/426 - 0s - loss: 0.4627 - acc: 0.8427\n",
      "Epoch 4/200\n",
      "426/426 - 0s - loss: 0.3699 - acc: 0.8709\n",
      "Epoch 5/200\n",
      "426/426 - 0s - loss: 0.3001 - acc: 0.8920\n",
      "Epoch 6/200\n",
      "426/426 - 0s - loss: 0.2550 - acc: 0.9085\n",
      "Epoch 7/200\n",
      "426/426 - 0s - loss: 0.2216 - acc: 0.9085\n",
      "Epoch 8/200\n",
      "426/426 - 0s - loss: 0.1886 - acc: 0.9296\n",
      "Epoch 9/200\n",
      "426/426 - 0s - loss: 0.1721 - acc: 0.9343\n",
      "Epoch 10/200\n",
      "426/426 - 0s - loss: 0.1598 - acc: 0.9390\n",
      "Epoch 11/200\n",
      "426/426 - 0s - loss: 0.1487 - acc: 0.9437\n",
      "Epoch 12/200\n",
      "426/426 - 0s - loss: 0.1370 - acc: 0.9507\n",
      "Epoch 13/200\n",
      "426/426 - 0s - loss: 0.1263 - acc: 0.9507\n",
      "Epoch 14/200\n",
      "426/426 - 0s - loss: 0.1183 - acc: 0.9671\n",
      "Epoch 15/200\n",
      "426/426 - 0s - loss: 0.1183 - acc: 0.9577\n",
      "Epoch 16/200\n",
      "426/426 - 0s - loss: 0.1033 - acc: 0.9695\n",
      "Epoch 17/200\n",
      "426/426 - 0s - loss: 0.0974 - acc: 0.9718\n",
      "Epoch 18/200\n",
      "426/426 - 0s - loss: 0.0932 - acc: 0.9742\n",
      "Epoch 19/200\n",
      "426/426 - 0s - loss: 0.0876 - acc: 0.9765\n",
      "Epoch 20/200\n",
      "426/426 - 0s - loss: 0.0839 - acc: 0.9836\n",
      "Epoch 21/200\n",
      "426/426 - 0s - loss: 0.0822 - acc: 0.9789\n",
      "Epoch 22/200\n",
      "426/426 - 0s - loss: 0.0780 - acc: 0.9789\n",
      "Epoch 23/200\n",
      "426/426 - 0s - loss: 0.0795 - acc: 0.9742\n",
      "Epoch 24/200\n",
      "426/426 - 0s - loss: 0.0737 - acc: 0.9765\n",
      "Epoch 25/200\n",
      "426/426 - 0s - loss: 0.0715 - acc: 0.9812\n",
      "Epoch 26/200\n",
      "426/426 - 0s - loss: 0.0703 - acc: 0.9765\n",
      "Epoch 27/200\n",
      "426/426 - 0s - loss: 0.0673 - acc: 0.9789\n",
      "Epoch 28/200\n",
      "426/426 - 0s - loss: 0.0618 - acc: 0.9789\n",
      "Epoch 29/200\n",
      "426/426 - 0s - loss: 0.0608 - acc: 0.9836\n",
      "Epoch 30/200\n",
      "426/426 - 0s - loss: 0.0599 - acc: 0.9836\n",
      "Epoch 31/200\n",
      "426/426 - 0s - loss: 0.0651 - acc: 0.9789\n",
      "Epoch 32/200\n",
      "426/426 - 0s - loss: 0.0566 - acc: 0.9812\n",
      "Epoch 33/200\n",
      "426/426 - 0s - loss: 0.0592 - acc: 0.9812\n",
      "Epoch 34/200\n",
      "426/426 - 0s - loss: 0.0553 - acc: 0.9836\n",
      "Epoch 35/200\n",
      "426/426 - 0s - loss: 0.0527 - acc: 0.9859\n",
      "Epoch 36/200\n",
      "426/426 - 0s - loss: 0.0548 - acc: 0.9859\n",
      "Epoch 37/200\n",
      "426/426 - 0s - loss: 0.0538 - acc: 0.9836\n",
      "Epoch 38/200\n",
      "426/426 - 0s - loss: 0.0501 - acc: 0.9836\n",
      "Epoch 39/200\n",
      "426/426 - 0s - loss: 0.0486 - acc: 0.9859\n",
      "Epoch 40/200\n",
      "426/426 - 0s - loss: 0.0469 - acc: 0.9859\n",
      "Epoch 41/200\n",
      "426/426 - 0s - loss: 0.0475 - acc: 0.9883\n",
      "Epoch 42/200\n",
      "426/426 - 0s - loss: 0.0450 - acc: 0.9883\n",
      "Epoch 43/200\n",
      "426/426 - 0s - loss: 0.0438 - acc: 0.9859\n",
      "Epoch 44/200\n",
      "426/426 - 0s - loss: 0.0433 - acc: 0.9883\n",
      "Epoch 45/200\n",
      "426/426 - 0s - loss: 0.0429 - acc: 0.9859\n",
      "Epoch 46/200\n",
      "426/426 - 0s - loss: 0.0455 - acc: 0.9883\n",
      "Epoch 47/200\n",
      "426/426 - 0s - loss: 0.0505 - acc: 0.9836\n",
      "Epoch 48/200\n",
      "426/426 - 0s - loss: 0.0472 - acc: 0.9836\n",
      "Epoch 49/200\n",
      "426/426 - 0s - loss: 0.0436 - acc: 0.9883\n",
      "Epoch 50/200\n",
      "426/426 - 0s - loss: 0.0395 - acc: 0.9859\n",
      "Epoch 51/200\n",
      "426/426 - 0s - loss: 0.0391 - acc: 0.9883\n",
      "Epoch 52/200\n",
      "426/426 - 0s - loss: 0.0469 - acc: 0.9836\n",
      "Epoch 53/200\n",
      "426/426 - 0s - loss: 0.0387 - acc: 0.9883\n",
      "Epoch 54/200\n",
      "426/426 - 0s - loss: 0.0449 - acc: 0.9883\n",
      "Epoch 55/200\n",
      "426/426 - 0s - loss: 0.0467 - acc: 0.9883\n",
      "Epoch 56/200\n",
      "426/426 - 0s - loss: 0.0384 - acc: 0.9883\n",
      "Epoch 57/200\n",
      "426/426 - 0s - loss: 0.0381 - acc: 0.9859\n",
      "Epoch 58/200\n",
      "426/426 - 0s - loss: 0.0346 - acc: 0.9906\n",
      "Epoch 59/200\n",
      "426/426 - 0s - loss: 0.0396 - acc: 0.9883\n",
      "Epoch 60/200\n",
      "426/426 - 0s - loss: 0.0396 - acc: 0.9859\n",
      "Epoch 61/200\n",
      "426/426 - 0s - loss: 0.0462 - acc: 0.9859\n",
      "Epoch 62/200\n",
      "426/426 - 0s - loss: 0.0470 - acc: 0.9789\n",
      "Epoch 63/200\n",
      "426/426 - 0s - loss: 0.0466 - acc: 0.9836\n",
      "Epoch 64/200\n",
      "426/426 - 0s - loss: 0.0464 - acc: 0.9765\n",
      "Epoch 65/200\n",
      "426/426 - 0s - loss: 0.0373 - acc: 0.9859\n",
      "Epoch 66/200\n",
      "426/426 - 0s - loss: 0.0393 - acc: 0.9859\n",
      "Epoch 67/200\n",
      "426/426 - 0s - loss: 0.0325 - acc: 0.9906\n",
      "Epoch 68/200\n",
      "426/426 - 0s - loss: 0.0311 - acc: 0.9906\n",
      "Epoch 69/200\n",
      "426/426 - 0s - loss: 0.0331 - acc: 0.9883\n",
      "Epoch 70/200\n",
      "426/426 - 0s - loss: 0.0294 - acc: 0.9906\n",
      "Epoch 71/200\n",
      "426/426 - 0s - loss: 0.0301 - acc: 0.9883\n",
      "Epoch 72/200\n",
      "426/426 - 0s - loss: 0.0349 - acc: 0.9836\n",
      "Epoch 73/200\n",
      "426/426 - 0s - loss: 0.0290 - acc: 0.9906\n",
      "Epoch 74/200\n",
      "426/426 - 0s - loss: 0.0345 - acc: 0.9836\n",
      "Epoch 75/200\n",
      "426/426 - 0s - loss: 0.0287 - acc: 0.9859\n",
      "Epoch 76/200\n",
      "426/426 - 0s - loss: 0.0373 - acc: 0.9906\n",
      "Epoch 77/200\n",
      "426/426 - 0s - loss: 0.0351 - acc: 0.9859\n",
      "Epoch 78/200\n",
      "426/426 - 0s - loss: 0.0378 - acc: 0.9836\n",
      "Epoch 79/200\n",
      "426/426 - 0s - loss: 0.0366 - acc: 0.9883\n",
      "Epoch 80/200\n",
      "426/426 - 0s - loss: 0.0285 - acc: 0.9883\n",
      "Epoch 81/200\n",
      "426/426 - 0s - loss: 0.0268 - acc: 0.9883\n",
      "Epoch 82/200\n",
      "426/426 - 0s - loss: 0.0254 - acc: 0.9906\n",
      "Epoch 83/200\n",
      "426/426 - 0s - loss: 0.0299 - acc: 0.9883\n",
      "Epoch 84/200\n",
      "426/426 - 0s - loss: 0.0305 - acc: 0.9859\n",
      "Epoch 85/200\n",
      "426/426 - 0s - loss: 0.0314 - acc: 0.9836\n",
      "Epoch 86/200\n",
      "426/426 - 0s - loss: 0.0393 - acc: 0.9883\n",
      "Epoch 87/200\n",
      "426/426 - 0s - loss: 0.0391 - acc: 0.9836\n",
      "Epoch 88/200\n",
      "426/426 - 0s - loss: 0.0256 - acc: 0.9930\n",
      "Epoch 89/200\n",
      "426/426 - 0s - loss: 0.0264 - acc: 0.9883\n",
      "Epoch 90/200\n",
      "426/426 - 0s - loss: 0.0305 - acc: 0.9883\n",
      "Epoch 91/200\n",
      "426/426 - 0s - loss: 0.0262 - acc: 0.9883\n",
      "Epoch 92/200\n",
      "426/426 - 0s - loss: 0.0247 - acc: 0.9883\n",
      "Epoch 93/200\n",
      "426/426 - 0s - loss: 0.0234 - acc: 0.9906\n",
      "Epoch 94/200\n",
      "426/426 - 0s - loss: 0.0219 - acc: 0.9953\n",
      "Epoch 95/200\n",
      "426/426 - 0s - loss: 0.0214 - acc: 0.9906\n",
      "Epoch 96/200\n",
      "426/426 - 0s - loss: 0.0236 - acc: 0.9883\n",
      "Epoch 97/200\n",
      "426/426 - 0s - loss: 0.0232 - acc: 0.9883\n",
      "Epoch 98/200\n",
      "426/426 - 0s - loss: 0.0336 - acc: 0.9812\n",
      "Epoch 99/200\n",
      "426/426 - 0s - loss: 0.0247 - acc: 0.9906\n",
      "Epoch 100/200\n",
      "426/426 - 0s - loss: 0.0202 - acc: 0.9930\n",
      "Epoch 101/200\n",
      "426/426 - 0s - loss: 0.0215 - acc: 0.9906\n",
      "Epoch 102/200\n",
      "426/426 - 0s - loss: 0.0213 - acc: 0.9883\n",
      "Epoch 103/200\n",
      "426/426 - 0s - loss: 0.0234 - acc: 0.9906\n",
      "Epoch 104/200\n",
      "426/426 - 0s - loss: 0.0177 - acc: 0.9930\n",
      "Epoch 105/200\n",
      "426/426 - 0s - loss: 0.0207 - acc: 0.9906\n",
      "Epoch 106/200\n",
      "426/426 - 0s - loss: 0.0187 - acc: 0.9953\n",
      "Epoch 107/200\n",
      "426/426 - 0s - loss: 0.0250 - acc: 0.9906\n",
      "Epoch 108/200\n",
      "426/426 - 0s - loss: 0.0226 - acc: 0.9930\n",
      "Epoch 109/200\n",
      "426/426 - 0s - loss: 0.0220 - acc: 0.9953\n",
      "Epoch 110/200\n",
      "426/426 - 0s - loss: 0.0259 - acc: 0.9883\n",
      "Epoch 111/200\n",
      "426/426 - 0s - loss: 0.0273 - acc: 0.9883\n",
      "Epoch 112/200\n",
      "426/426 - 0s - loss: 0.0194 - acc: 0.9977\n",
      "Epoch 113/200\n",
      "426/426 - 0s - loss: 0.0192 - acc: 0.9953\n",
      "Epoch 114/200\n",
      "426/426 - 0s - loss: 0.0166 - acc: 0.9953\n",
      "Epoch 115/200\n",
      "426/426 - 0s - loss: 0.0158 - acc: 0.9953\n",
      "Epoch 116/200\n",
      "426/426 - 0s - loss: 0.0179 - acc: 0.9883\n",
      "Epoch 117/200\n",
      "426/426 - 0s - loss: 0.0162 - acc: 0.9906\n",
      "Epoch 118/200\n",
      "426/426 - 0s - loss: 0.0161 - acc: 0.9977\n",
      "Epoch 119/200\n",
      "426/426 - 0s - loss: 0.0200 - acc: 0.9883\n",
      "Epoch 120/200\n",
      "426/426 - 0s - loss: 0.0156 - acc: 0.9953\n",
      "Epoch 121/200\n",
      "426/426 - 0s - loss: 0.0169 - acc: 0.9906\n",
      "Epoch 122/200\n",
      "426/426 - 0s - loss: 0.0158 - acc: 0.9953\n",
      "Epoch 123/200\n",
      "426/426 - 0s - loss: 0.0163 - acc: 0.9953\n",
      "Epoch 124/200\n",
      "426/426 - 0s - loss: 0.0162 - acc: 0.9930\n",
      "Epoch 125/200\n",
      "426/426 - 0s - loss: 0.0271 - acc: 0.9906\n",
      "Epoch 126/200\n",
      "426/426 - 0s - loss: 0.0172 - acc: 0.9930\n",
      "Epoch 127/200\n",
      "426/426 - 0s - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 128/200\n",
      "426/426 - 0s - loss: 0.0155 - acc: 0.9953\n",
      "Epoch 129/200\n",
      "426/426 - 0s - loss: 0.0146 - acc: 0.9930\n",
      "Epoch 130/200\n",
      "426/426 - 0s - loss: 0.0162 - acc: 0.9977\n",
      "Epoch 131/200\n",
      "426/426 - 0s - loss: 0.0202 - acc: 0.9883\n",
      "Epoch 132/200\n",
      "426/426 - 0s - loss: 0.0122 - acc: 0.9977\n",
      "Epoch 133/200\n",
      "426/426 - 0s - loss: 0.0135 - acc: 0.9953\n",
      "Epoch 134/200\n",
      "426/426 - 0s - loss: 0.0122 - acc: 0.9953\n",
      "Epoch 135/200\n",
      "426/426 - 0s - loss: 0.0236 - acc: 0.9859\n",
      "Epoch 136/200\n",
      "426/426 - 0s - loss: 0.0112 - acc: 1.0000\n",
      "Epoch 137/200\n",
      "426/426 - 0s - loss: 0.0140 - acc: 0.9930\n",
      "Epoch 138/200\n",
      "426/426 - 0s - loss: 0.0114 - acc: 0.9977\n",
      "Epoch 139/200\n",
      "426/426 - 0s - loss: 0.0175 - acc: 0.9930\n",
      "Epoch 140/200\n",
      "426/426 - 0s - loss: 0.0142 - acc: 0.9953\n",
      "Epoch 141/200\n",
      "426/426 - 0s - loss: 0.0155 - acc: 0.9977\n",
      "Epoch 142/200\n",
      "426/426 - 0s - loss: 0.0185 - acc: 0.9930\n",
      "Epoch 143/200\n",
      "426/426 - 0s - loss: 0.0152 - acc: 0.9930\n",
      "Epoch 144/200\n",
      "426/426 - 0s - loss: 0.0206 - acc: 0.9906\n",
      "Epoch 145/200\n",
      "426/426 - 0s - loss: 0.0191 - acc: 0.9906\n",
      "Epoch 146/200\n",
      "426/426 - 0s - loss: 0.0258 - acc: 0.9883\n",
      "Epoch 147/200\n",
      "426/426 - 0s - loss: 0.0214 - acc: 0.9930\n",
      "Epoch 148/200\n",
      "426/426 - 0s - loss: 0.0198 - acc: 0.9906\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426/426 - 0s - loss: 0.0114 - acc: 0.9977\n",
      "Epoch 150/200\n",
      "426/426 - 0s - loss: 0.0125 - acc: 0.9953\n",
      "Epoch 151/200\n",
      "426/426 - 0s - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 152/200\n",
      "426/426 - 0s - loss: 0.0092 - acc: 0.9977\n",
      "Epoch 153/200\n",
      "426/426 - 0s - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 154/200\n",
      "426/426 - 0s - loss: 0.0094 - acc: 0.9977\n",
      "Epoch 155/200\n",
      "426/426 - 0s - loss: 0.0101 - acc: 0.9977\n",
      "Epoch 156/200\n",
      "426/426 - 0s - loss: 0.0097 - acc: 0.9977\n",
      "Epoch 157/200\n",
      "426/426 - 0s - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 158/200\n",
      "426/426 - 0s - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 159/200\n",
      "426/426 - 0s - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 160/200\n",
      "426/426 - 0s - loss: 0.0157 - acc: 0.9930\n",
      "Epoch 161/200\n",
      "426/426 - 0s - loss: 0.0090 - acc: 0.9977\n",
      "Epoch 162/200\n",
      "426/426 - 0s - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 163/200\n",
      "426/426 - 0s - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 164/200\n",
      "426/426 - 0s - loss: 0.0102 - acc: 0.9977\n",
      "Epoch 165/200\n",
      "426/426 - 0s - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 166/200\n",
      "426/426 - 0s - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 167/200\n",
      "426/426 - 0s - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 168/200\n",
      "426/426 - 0s - loss: 0.0079 - acc: 0.9977\n",
      "Epoch 169/200\n",
      "426/426 - 0s - loss: 0.0095 - acc: 0.9953\n",
      "Epoch 170/200\n",
      "426/426 - 0s - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 171/200\n",
      "426/426 - 0s - loss: 0.0077 - acc: 0.9977\n",
      "Epoch 172/200\n",
      "426/426 - 0s - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 173/200\n",
      "426/426 - 0s - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 174/200\n",
      "426/426 - 0s - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 175/200\n",
      "426/426 - 0s - loss: 0.0101 - acc: 0.9977\n",
      "Epoch 176/200\n",
      "426/426 - 0s - loss: 0.0086 - acc: 0.9977\n",
      "Epoch 177/200\n",
      "426/426 - 0s - loss: 0.0218 - acc: 0.9906\n",
      "Epoch 178/200\n",
      "426/426 - 0s - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 179/200\n",
      "426/426 - 0s - loss: 0.0120 - acc: 0.9977\n",
      "Epoch 180/200\n",
      "426/426 - 0s - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 181/200\n",
      "426/426 - 0s - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 182/200\n",
      "426/426 - 0s - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 183/200\n",
      "426/426 - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 184/200\n",
      "426/426 - 0s - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 185/200\n",
      "426/426 - 0s - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 186/200\n",
      "426/426 - 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 187/200\n",
      "426/426 - 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 188/200\n",
      "426/426 - 0s - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 189/200\n",
      "426/426 - 0s - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 190/200\n",
      "426/426 - 0s - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 191/200\n",
      "426/426 - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 192/200\n",
      "426/426 - 0s - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 193/200\n",
      "426/426 - 0s - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 194/200\n",
      "426/426 - 0s - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 195/200\n",
      "426/426 - 0s - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 196/200\n",
      "426/426 - 0s - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 197/200\n",
      "426/426 - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 198/200\n",
      "426/426 - 0s - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 199/200\n",
      "426/426 - 0s - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 200/200\n",
      "426/426 - 0s - loss: 0.0050 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a2d337198>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "deep_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train_categorical,\n",
    "    epochs=200,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes: [1 0 0 1 0 0 0 0 0 1]\n",
      "Actual Labels: [1, 0, 1, 1, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions \n",
    "encoded_predictions = deep_model.predict_classes(X_test_scaled[:10])\n",
    "prediction_labels = label_encoder.inverse_transform(encoded_predictions)\n",
    "print(f\"Predicted classes: {prediction_labels}\")\n",
    "print(f\"Actual Labels: {list(y_test)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143/143 [==============================] - 0s 366us/sample - loss: 0.0468 - acc: 0.9790\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.046766977210144896, 0.97902095]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score!\n",
    "deep_model.evaluate(X_test_scaled, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-encode data set\n",
    "\n",
    "# label_encoder = LabelEncoder()\n",
    "# label_encoder.fit(y)\n",
    "# encoded_y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine accuracy metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy measures and determine best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancer_model.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If model is the best model to be found, save the model\n",
    "# Update this when we figure out the best model; for now testing based on rf\n",
    "\n",
    "dump(rf, 'cancer_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
